{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import argparse\n",
    "import os\n",
    "import copy\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    parser.add_argument('--annot_train_prime', type = str, default = 'df_prime_train_features.csv')\n",
    "    parser.add_argument('--annot_test_prime', type = str, default = 'df_prime_test_features.csv')\n",
    "    parser.add_argument('--data_root', type = str, default = '/usr/scratch/abhimanyu/courses/ECE8803_FML/OLIVES')\n",
    "    parser.add_argument('--data_aug', type =int, default = 1)\n",
    "    \n",
    "    \n",
    "    return parser.parse_known_args()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(device)\n",
    "    args, unkown = parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_dataloader(args, file = 'df_prime_train_features.csv'):\n",
    "    LABELS_Severity = {35: 0,\n",
    "                    43: 0,\n",
    "                    47: 1,\n",
    "                    53: 1,\n",
    "                    61: 2,\n",
    "                    65: 2,\n",
    "                    71: 2,\n",
    "                    85: 2}\n",
    "\n",
    "\n",
    "    annot = pd.read_csv(file)\n",
    "    annot['Severity_Label'] = [LABELS_Severity[drss] for drss in copy.deepcopy(annot['DRSS'].values)]\n",
    "\n",
    "    path_list = annot['Volume_ID'].values\n",
    "\n",
    "    labels = annot['Severity_Label'].values.reshape(-1,1)\n",
    "    # print(labels)\n",
    "    # assert len(path_list) == len(labels)\n",
    "    root = os.path.expanduser(args.data_root)\n",
    "\n",
    "\n",
    "    img_volume = []\n",
    "\n",
    "    # for index in range(20):\n",
    "    for index in range(len(path_list)):\n",
    "        # img_volume[index] = []\n",
    "        frames = []\n",
    "        folder_path = root + path_list[index]\n",
    "\n",
    "        # if index%10 == 0  :\n",
    "            # print(f\"Completed {index} images\")\n",
    "        \n",
    "        starting_frame = 10\n",
    "        for i in range(10, 39): \n",
    "            tif = str(i) + '.tif'\n",
    "            png = str(i) + '.png'\n",
    "            \n",
    "            if (os.path.isfile(os.path.join(folder_path, tif))):\n",
    "                img = Image.open(os.path.join(folder_path, tif)).convert(\"L\")\n",
    "            elif (os.path.isfile(os.path.join(folder_path, png))):\n",
    "                img = Image.open(os.path.join(folder_path, png)).convert(\"L\")\n",
    "            else:\n",
    "                img = frames[i -starting_frame - 1]\n",
    "                frames.append(frames[i -starting_frame - 1])\n",
    "                continue\n",
    "            frames.append(np.asarray(img)[106:224,80:450])\n",
    "\n",
    "\n",
    "        img_volume.append(np.array(frames))\n",
    "\n",
    "    print(np.shape(img_volume))\n",
    "    img_volume =np.reshape(img_volume,(len(img_volume), -1)) \n",
    "    # ret = img_volume.reshape((len(img_volume), -1))\n",
    "    print(np.shape(labels))\n",
    "\n",
    "    return img_volume, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(495, 29, 118, 370)\n",
      "(495, 1)\n",
      "(163, 29, 118, 370)\n",
      "(163, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load your 3D image dataset\n",
    "# Assuming your dataset is loaded into a PyTorch tensor called `data` with shape (num_samples, num_features)\n",
    "# and the corresponding labels are loaded into a PyTorch tensor called `labels` with shape (num_samples,)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, y_train = knn_dataloader(args, args.annot_train_prime )\n",
    "X_test, y_test = knn_dataloader(args, args.annot_test_prime ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/scratch/abhimanyu/work/miniconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4356, Balanced Accuracy: 0.4029\n"
     ]
    }
   ],
   "source": [
    "# Create and train KNN classifier\n",
    "k = 6  # Number of neighbors\n",
    "clf = KNeighborsClassifier(n_neighbors=k)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "balanced_accuracy = balanced_accuracy_score(y_test,y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}, Balanced Accuracy: {balanced_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(predictions, labels, num_classes):\n",
    "  recalls = []\n",
    "\n",
    "  TP = np.zeros(num_classes)\n",
    "  TN = np.zeros(num_classes)\n",
    "  FP = np.zeros(num_classes)\n",
    "  FN = np.zeros(num_classes)\n",
    "\n",
    "  for i in range(num_classes):\n",
    "    y_true = labels == i\n",
    "    y_pred = predictions == i\n",
    "\n",
    "    TN[i], FP[i], FN[i], TP[i] = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "  return TP, TN, FP, FN\n",
    "\n",
    "def get_eval(TP, TN, FP, FN, num_classes):\n",
    "  macro_avg_precision = 0\n",
    "  macro_avg_sensitivity = 0\n",
    "  macro_avg_f1 = 0\n",
    "  macro_avg_specification = 0\n",
    "  \n",
    "  \n",
    "  for i in range(num_classes):\n",
    "    macro_avg_precision += TP[i] / (TP[i] + FP[i])\n",
    "    macro_avg_sensitivity += TP[i] / (TP[i] + FN[i])\n",
    "    macro_avg_specification += TN[i] / (FP[i] + TN[i])\n",
    "\n",
    "  macro_avg_precision /= num_classes\n",
    "  macro_avg_sensitivity /= num_classes\n",
    "  macro_avg_specification /= num_classes\n",
    "\n",
    "  macro_avg_f1 = 2 * (macro_avg_precision * macro_avg_sensitivity) / (macro_avg_precision + macro_avg_sensitivity)\n",
    "\n",
    "  return macro_avg_precision, macro_avg_sensitivity, macro_avg_specification, macro_avg_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macro_avg_precision:  0.40294665012406944\n",
      "macro_avg_sensitivity/recall:  0.39387874690105923\n",
      "macro_avg_specificity:  0.7187738367658275\n",
      "macro_avg_f1:  0.39836110197135916\n"
     ]
    }
   ],
   "source": [
    "TP, TN, FP, FN = get_stats(y_test,y_pred, 3)\n",
    "macro_avg_precision, macro_avg_sensitivity, macro_avg_specification, macro_avg_f1 = get_eval(TP, TN, FP, FN, 3)\n",
    "print('macro_avg_precision: ', macro_avg_precision)\n",
    "print('macro_avg_sensitivity/recall: ', macro_avg_sensitivity)\n",
    "print('macro_avg_specificity: ', macro_avg_specification)\n",
    "print('macro_avg_f1: ', macro_avg_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('ViT test best.pickle','rb') as f:\n",
    "  feature_dict = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4233, Balanced Accuracy: 0.4066\n"
     ]
    }
   ],
   "source": [
    "# print(feature_dict)\n",
    "test_features = feature_dict['prediction']\n",
    "test_labels = feature_dict['label']\n",
    "accuracy = accuracy_score(y_pred=test_features,y_true=test_labels)\n",
    "balanced_accuracy = balanced_accuracy_score(y_pred=test_features,y_true=test_labels)\n",
    "print(f\"Accuracy: {accuracy:.4f}, Balanced Accuracy: {balanced_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macro_avg_precision:  0.40662737799834575\n",
      "macro_avg_sensitivity/recall:  0.404904214559387\n",
      "macro_avg_specificity:  0.7056296043138149\n",
      "macro_avg_f1:  0.40576396684162414\n"
     ]
    }
   ],
   "source": [
    "TP, TN, FP, FN = get_stats(test_labels,test_features, 3)\n",
    "macro_avg_precision, macro_avg_sensitivity, macro_avg_specification, macro_avg_f1 = get_eval(TP, TN, FP, FN, 3)\n",
    "print('macro_avg_precision: ', macro_avg_precision)\n",
    "print('macro_avg_sensitivity/recall: ', macro_avg_sensitivity)\n",
    "print('macro_avg_specificity: ', macro_avg_specification)\n",
    "print('macro_avg_f1: ', macro_avg_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
